{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b841868d-4cf1-4fcf-9e93-9ddee582b82e",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3218139-816a-412d-8a19-1bbfb219ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "from jestimator import amos            # The Amos optimizer implementation\n",
    "from jestimator import amos_helper     # Helper module for Amos\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import math\n",
    "import tensorflow_datasets as tfds     # TFDS for MNIST\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ea98c-080c-4ca8-bbc5-276c95d8196e",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11a52ce-e9e4-490a-94d6-d76758305729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "\n",
    "  ds_builder = tfds.builder('mnist')\n",
    "  ds_builder.download_and_prepare()\n",
    "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996a480-b5dc-48b1-8fc1-d65c38aa9100",
   "metadata": {},
   "source": [
    "### 3. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e81e1c5-30db-4ad3-a67d-ebab67a5c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # flatten\n",
    "    x = nn.Dense(features=256)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=10)(x)\n",
    "    return x\n",
    "\n",
    "  def classify_xe_loss(self, x, labels):\n",
    "    # Labels read from the tfds MNIST are integers from 0 to 9.  \n",
    "    # Logits are arrays of size 10.\n",
    "    logits = self(x)\n",
    "    logits = jax.nn.log_softmax(logits)\n",
    "    labels_ = jnp.expand_dims(labels, -1)\n",
    "    llh_ = jnp.take_along_axis(logits, labels_, axis=-1)\n",
    "    loss = -jnp.sum(llh_)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71146ddd-6e10-4bb8-9e7f-4fc8f952a6e9",
   "metadata": {},
   "source": [
    "### 4. Create train state\n",
    "\n",
    "A `TrainState` object keeps the model parameters and optimizer states, and can be checkpointed into files.\n",
    "\n",
    "We create the model and optimizer in this function.\n",
    "\n",
    "**For the optimizer, we use Amos here.** The following hyper-parameters are set:\n",
    "\n",
    " * *learning_rate*:       The global learning rate.\n",
    " * *eta_fn*:              The model-specific 'eta'.\n",
    " * *shape_fn*:            Memory reduction setting.\n",
    " * *beta*:                Rate for running average of gradient squares.\n",
    " * *clip_value*:          Gradient clipping for stable training.\n",
    "\n",
    "The global learning rate is usually set to the 1/sqrt(N), where N is the number of batches in the training data. For MNIST, we have 60k training examples and batch size is 32. So learning_rate=1/sqrt(60000/32).\n",
    "\n",
    "The model-specific 'eta_fn' requires a function that, given a variable name and shape, returns a float indicating the expected scale of that variable. Hopefully in the near future we will have libraries that can automatically calculate this 'eta_fn' from the modeling code; but for now we have to specify it manually.\n",
    "\n",
    "One can use the amos_helper.params_fn_from_assign_map() helper function to create 'eta_fn' from an assign_map. An assign_map is a dict which maps regex rules to a value or simple Python expressions. It will find the first regex rule which matches the name of a variable, and evaluate the Python expression if necessary to return the value. See our example below.\n",
    "\n",
    "The 'shape_fn' similarly requires a function that, given a variable name and shape, returns a reduced shape for the corresponding slot variables. We can use the amos_helper.params_fn_from_assign_map() helper function to create 'shape_fn' from an assign_map as well.\n",
    "\n",
    "'beta' is the exponential decay rate for running average of gradient squares. We set it to 0.98 here.\n",
    "\n",
    "'clip_value' is the gradient clipping value, which should match the magnitude of the loss function. If the loss function is a sum of cross-entropy, then we should set 'clip_value' to the sqrt of the number of labels.\n",
    "\n",
    "Please refer to our [paper](https://arxiv.org/abs/2210.11693) for more details of the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb049df8-70dc-447c-9a11-7166feb12d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_state(rng):\n",
    "  model = CNN()\n",
    "  dummy_x = jnp.ones([1, 28, 28, 1])\n",
    "  params = model.init(rng, dummy_x)\n",
    "\n",
    "  eta_fn = amos_helper.params_fn_from_assign_map(\n",
    "      {\n",
    "          '.*/bias': 0.5,\n",
    "          '.*Conv_0/kernel': 'sqrt(8/prod(SHAPE[:-1]))',\n",
    "          '.*Conv_1/kernel': 'sqrt(2/prod(SHAPE[:-1]))',\n",
    "          '.*Dense_0/kernel': 'sqrt(2/SHAPE[0])',\n",
    "          '.*Dense_1/kernel': 'sqrt(1/SHAPE[0])',\n",
    "      },\n",
    "      eval_str_value=True,\n",
    "  )\n",
    "  shape_fn = amos_helper.params_fn_from_assign_map(\n",
    "      {\n",
    "          '.*Conv_[01]/kernel': '(1, 1, 1, SHAPE[-1])',\n",
    "          '.*Dense_0/kernel': '(1, SHAPE[1])',\n",
    "          '.*': (),\n",
    "      },\n",
    "      eval_str_value=True,\n",
    "  )\n",
    "  optimizer = amos.amos(\n",
    "      learning_rate=1/math.sqrt(60000/32),\n",
    "      eta_fn=eta_fn,\n",
    "      shape_fn=shape_fn,\n",
    "      beta=0.98,\n",
    "      clip_value=math.sqrt(32),\n",
    "  )\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=model.apply, params=params, tx=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00564e-504e-4275-b80a-8deed0fde177",
   "metadata": {},
   "source": [
    "### 5. Training step\n",
    "\n",
    "Use JAX’s @jit decorator to just-in-time compile the function for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca15ee35-eb1d-4685-8e98-568c1cafc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(batch, state):\n",
    "  grad_fn = jax.grad(state.apply_fn)\n",
    "  grads = grad_fn(\n",
    "      state.params,\n",
    "      batch['image'],\n",
    "      batch['label'],\n",
    "      method=CNN.classify_xe_loss)\n",
    "  return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a64e7-5507-49aa-8399-c3f20aa72a0e",
   "metadata": {},
   "source": [
    "### 6. Infer step\n",
    "\n",
    "Use JAX’s @jit decorator to just-in-time compile the function for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5ef40d-7fac-479f-ad5f-8bda7f839b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def infer_step(batch, state):\n",
    "  logits = state.apply_fn(state.params, batch['image'])\n",
    "  return jnp.argmax(logits, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429829e-2f7a-4fb6-acff-d4caaa3a20f6",
   "metadata": {},
   "source": [
    "### 7. Main\n",
    "\n",
    "Run the training loop and evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b181696-9268-4f8e-b359-249a544c53b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test accuracy: 97.28\n",
      "epoch: 2, test accuracy: 98.46\n",
      "epoch: 3, test accuracy: 98.63\n",
      "epoch: 4, test accuracy: 97.91\n",
      "epoch: 5, test accuracy: 98.59\n",
      "epoch: 6, test accuracy: 99.05\n",
      "epoch: 7, test accuracy: 99.15\n",
      "epoch: 8, test accuracy: 99.21\n",
      "epoch: 9, test accuracy: 99.26\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "state = get_train_state(init_rng)\n",
    "del init_rng  # Must not be used anymore.\n",
    "\n",
    "num_epochs = 9\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  # Use a separate PRNG key to permute image data during shuffling\n",
    "  rng, input_rng = jax.random.split(rng)\n",
    "  perms = jax.random.permutation(input_rng, 60000)\n",
    "  del input_rng\n",
    "  perms = perms.reshape((60000 // 32, 32))\n",
    "  for perm in perms:\n",
    "    batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "    state = train_step(batch, state)\n",
    "\n",
    "  pred = jax.device_get(infer_step(test_ds, state))\n",
    "  accuracy = accuracy_score(test_ds['label'], pred)\n",
    "  print('epoch: %d, test accuracy: %.2f' % (epoch, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236e19d-3fa1-43b0-90d4-a29df8613deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
